{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJt+Ur+KV+PJwADIFwWSJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresgd17/MLProject_HandLearRecog/blob/main/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project 3\n",
        "\n",
        "We load the mfeat-pix.txt data file"
      ],
      "metadata": {
        "id": "BKmBlb_AHL8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy  as np\n",
        "from numpy.linalg import inv\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "\n",
        "mfeat_pix = pd.read_csv('mfeat-pix.txt',sep='\\s+',header=None)\n",
        "mfeat_pix = pd.DataFrame(mfeat_pix)\n",
        "rows = 15\n",
        "cols = 16"
      ],
      "metadata": {
        "id": "k8d_vN-DHKhu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickIndices_trainFinal = [j+200*i for i in range(0, 10, 1) for j in range(0, 180, 1)]\n",
        "pickIndices_testFinal = [j - 20 + 200*(i+1) for i in range(0, 10, 1) for j in range(0, 20, 1)]\n",
        "\n",
        "#print(pickIndices_trainFinal)\n",
        "#print(pickIndices_testFinal)\n",
        "meanTrainImagesFinal = [([0]*10) for i in range(240)]\n",
        "\n",
        "trainPatternsFinal = []\n",
        "testPatternsFinal  = []\n",
        "\n",
        "for i in pickIndices_trainFinal:\n",
        "    temp_trainFinal = []\n",
        "    for j in range(rows*cols):\n",
        "        temp_trainFinal.append(mfeat_pix[j][i])\n",
        "        #temp_testFinal.append(mfeat_pix[j][i+100])\n",
        "    trainPatternsFinal.append(temp_trainFinal)\n",
        "    #testPatternsFinal.append(temp_testFinal)\n",
        "\n",
        "for i in pickIndices_testFinal:\n",
        "    temp_testFinal = []\n",
        "    for j in range(rows*cols):\n",
        "        #temp_trainFinal.append(mfeat_pix[j][i])\n",
        "        temp_testFinal.append(mfeat_pix[j][i])\n",
        "    #trainPatternsFinal.append(temp_trainFinal)\n",
        "    testPatternsFinal.append(temp_testFinal)\n"
      ],
      "metadata": {
        "id": "aUhfQGFAIWQq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and define the function to split data into training and test data"
      ],
      "metadata": {
        "id": "l_hFqRLZDRfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HHBM_7sMCezH"
      },
      "outputs": [],
      "source": [
        "def cross_validation_split(trainPatternsFinal):\n",
        "  #split to 160 training and 20 testing data for cross validation\n",
        "  pickIndices_train = [j+180*i for i in range(0, 10, 1) for j in range(0, 180, 1)]\n",
        "  pickIndices_test = []\n",
        "  number_of_tests = 20\n",
        "  number_of_digits = 10\n",
        "  for i in range(number_of_digits):\n",
        "    j = 0\n",
        "    while j < number_of_tests:\n",
        "      tmp_pick = 180*i + int(np.random.uniform()*180)\n",
        "      if tmp_pick in pickIndices_test:\n",
        "        j -= 1\n",
        "      else:\n",
        "        pickIndices_test.append(tmp_pick) \n",
        "      j += 1\n",
        "  pickIndices_test.sort()\n",
        "  for obj in pickIndices_test:\n",
        "    pickIndices_train.remove(obj)\n",
        "  #print(pickIndices_train)\n",
        "  #print(pickIndices_test)\n",
        "  #meanTrainImages = [([0]*10) for i in range(240)]\n",
        "\n",
        "  trainPatterns = []\n",
        "  testPatterns  = []\n",
        "\n",
        "  for i in pickIndices_train:\n",
        "      temp_train = []\n",
        "      #print(i)\n",
        "      for j in range(rows*cols):\n",
        "          temp_train.append(trainPatternsFinal[i][j])  \n",
        "      trainPatterns.append(temp_train)\n",
        "\n",
        "  for i in pickIndices_test:\n",
        "      temp_test = []\n",
        "      for j in range(rows*cols):\n",
        "          temp_test.append(trainPatternsFinal[i][j])\n",
        "      testPatterns.append(temp_test)\n",
        "  \n",
        "  meanTrainImages = [] #240x10\n",
        "\n",
        "  for i in range(0, 240):\n",
        "    temp = []\n",
        "    for j in range(0,10):\n",
        "        mean = 0\n",
        "        for k in range(j*160,(j+1)*160):\n",
        "            mean += trainPatterns[k][i]\n",
        "        #print(i,j*100,(j+1)*100, \"mean: \", mean) \n",
        "        temp.append(mean/160)\n",
        "    meanTrainImages.append(temp)\n",
        "\n",
        "  #pd.DataFrame(meanTrainImages)\n",
        "\n",
        "  #pd.DataFrame(trainPatterns)\n",
        "  ##pd.DataFrame(pickIndices_train)\n",
        "  #pd.DataFrame(pickIndices_test)\n",
        "  return trainPatterns, testPatterns, meanTrainImages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define three more functions :\n",
        "\n",
        "\n",
        "*   training function\n",
        "*   best model\n",
        "*   nrOfMisclassificationsTrain\n",
        "\n"
      ],
      "metadata": {
        "id": "adcg_ff8EMt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nrOfMisclassificationsTrain(A,B):\n",
        "    sum = 0\n",
        "    for i in range(len(A[0])):\n",
        "        if (A[0][i] != B[0][i]):\n",
        "            sum += 1\n",
        "    return sum\n",
        "    \n",
        "def trainingFunction(trainPatterns, testPatterns, meanTrainImages):\n",
        "  ###################################################################################\n",
        "  ### defining the trainlabels   160 IS THE NUMBER OF DATA\n",
        "  b = np.ones(160)\n",
        "  trainLabels = block_diag(*([b] * 10))\n",
        "  testLabels  = trainLabels\n",
        "\n",
        "  ### create a row vector of correct class labels (from 1 ... 10 for the 10 classes). \n",
        "  ### This vector is the not the same for training and testing.  \n",
        "  ### 160 IS FOR THE TRAINING \n",
        "  ###  20 IS FOR THE TESTING\n",
        "  ### Corrrelabels for training data\n",
        "  correctLabelsTrain, tmpTrain = [], []\n",
        "  for i in range(0, 10):\n",
        "      for j in range(i*160, (1+i)*160):\n",
        "          tmpTrain.append(i+1)\n",
        "  correctLabelsTrain.append(tmpTrain)\n",
        "\n",
        "  ### Correct labels for test data\n",
        "  correctLabelsTest, tmpTest = [], []\n",
        "  for i in range(0, 10):\n",
        "      for j in range(i*20, (1+i)*20):\n",
        "          tmpTest.append(i+1)\n",
        "  correctLabelsTest.append(tmpTest)\n",
        "  ##################################################################################\n",
        "\n",
        "  ### Defining the X matrix given by featureValuesTrain\n",
        "  featureValuesTrain = np.dot(np.transpose(meanTrainImages), np.transpose(trainPatterns))\n",
        "  featureValuesTest  = np.dot(np.transpose(meanTrainImages), np.transpose(testPatterns))\n",
        "\n",
        "  ### Computing the weights matrix W\n",
        "  XX =  (inv(np.dot(featureValuesTrain, np.transpose(featureValuesTrain))))\n",
        "  W  = np.dot(np.dot(XX,featureValuesTrain), np.transpose(trainLabels))\n",
        "  W  = np.transpose(W)\n",
        "\n",
        "  ### Computing the loss function with nrOfMisclassifications on TRAINING DATA\n",
        "  classificationHypothesesTrain = np.dot(W,featureValuesTrain)\n",
        "\n",
        "  maxValues, maxIndicesTrain = [], []\n",
        "  maxValues_temp, maxIndicesTrain_temp = [], []\n",
        "  for i in range(0, len(classificationHypothesesTrain[0])):\n",
        "      index = np.argmax(np.asarray(classificationHypothesesTrain[:,i]))\n",
        "      value = classificationHypothesesTrain[index][i]\n",
        "      maxValues_temp.append(value)\n",
        "      maxIndicesTrain_temp.append(index+1)\n",
        "\n",
        "  maxValues.append(maxValues_temp)\n",
        "  maxIndicesTrain.append(maxIndicesTrain_temp)\n",
        "  \n",
        "  trainMisclassificationRate = 100* nrOfMisclassificationsTrain(correctLabelsTrain,maxIndicesTrain) / len(classificationHypothesesTrain[0])\n",
        "\n",
        "  ### Computing the loss function with nrOfMisclassifications on TEST DATA\n",
        "  classificationHypothesesTest = np.dot(W,featureValuesTest)\n",
        "  maxValuesTest, maxIndicesTest = [], []\n",
        "  maxValuesTest_temp, maxIndicesTest_temp = [], []\n",
        "\n",
        "  for i in range(0, len(classificationHypothesesTest[0])):\n",
        "      index = np.argmax(np.asarray(classificationHypothesesTest[:,i]))\n",
        "      value = classificationHypothesesTest[index][i]\n",
        "      maxValuesTest_temp.append(value)\n",
        "      maxIndicesTest_temp.append(index+1)\n",
        "\n",
        "  maxValuesTest.append(maxValuesTest_temp)\n",
        "  maxIndicesTest.append(maxIndicesTest_temp)\n",
        "\n",
        "  testMisclassificationRate = 100 * nrOfMisclassificationsTrain(correctLabelsTest,maxIndicesTest) / len(classificationHypothesesTest[0])\n",
        "\n",
        "  return W, trainMisclassificationRate, testMisclassificationRate\n",
        "\n",
        "def bestmodel(W, mean_meanTrainImages, testPatternsFinal):\n",
        "  ###################################################################################\n",
        "  ### create a row vector of correct class labels (from 1 ... 10 for the 10 classes). \n",
        "  ### This vector is the not the same for training and testing.  \n",
        "  ###  20 IS FOR THE TESTING\n",
        "  ### Correct labels for test data\n",
        "  correctLabelsTest, tmpTest = [], []\n",
        "  for i in range(0, 10):\n",
        "      for j in range(i*20, (1+i)*20):\n",
        "          tmpTest.append(i+1)\n",
        "  correctLabelsTest.append(tmpTest)\n",
        "  ##################################################################################\n",
        "\n",
        "  ### Defining the X matrix given by featureValuesTest\n",
        "  featureValuesTest  = np.dot(np.transpose(mean_meanTrainImages), np.transpose(testPatternsFinal))\n",
        "\n",
        "  ### Computing the loss function with nrOfMisclassifications on TEST DATA\n",
        "  classificationHypothesesTest = np.dot(W,featureValuesTest)\n",
        "  maxValuesTest, maxIndicesTest = [], []\n",
        "  maxValuesTest_temp, maxIndicesTest_temp = [], []\n",
        "\n",
        "  for i in range(0, len(classificationHypothesesTest[0])):\n",
        "      index = np.argmax(np.asarray(classificationHypothesesTest[:,i]))\n",
        "      value = classificationHypothesesTest[index][i]\n",
        "      maxValuesTest_temp.append(value)\n",
        "      maxIndicesTest_temp.append(index+1)\n",
        "\n",
        "  maxValuesTest.append(maxValuesTest_temp)\n",
        "  maxIndicesTest.append(maxIndicesTest_temp)\n",
        "\n",
        "  testMisclassificationRate = 100 * nrOfMisclassificationsTrain(correctLabelsTest,maxIndicesTest) / len(classificationHypothesesTest[0])\n",
        "\n",
        "  return testMisclassificationRate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7SONLygGDq-z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconstruction on ultimate final test data"
      ],
      "metadata": {
        "id": "BC-2F227FMWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_Weights, array_train_error, array_test_error = [], [], []\n",
        "mean_Weights = [ [ 0 for i in range(10) ] for j in range(10) ]          #### Matrix with mean weigths\n",
        "mean_meanTrainImages = [ [ 0 for i in range(10) ] for j in range(240) ] #### Matrix with mean of the meanTrainImages\n",
        "\n",
        "nIterations = 10\n",
        "\n",
        "for i in range (nIterations):\n",
        "  x, y, z = cross_validation_split(trainPatternsFinal)\n",
        "  Weights, train_error, test_error = trainingFunction(x,y,z)\n",
        "  print(\"iteration: \", i, \"Weights: \", np.shape(Weights), \"% train_error: \",train_error, \"   % test_error: \",test_error)\n",
        "  \n",
        "  array_Weights.append(Weights)\n",
        "  array_train_error.append(train_error)\n",
        "  array_test_error.append(test_error)\n",
        "\n",
        "  mean_Weights += Weights\n",
        "  mean_meanTrainImages += np.array(z)\n",
        "\n",
        "mean_Weights /= nIterations\n",
        "mean_meanTrainImages /= nIterations\n",
        "\n",
        "print(\"% mean train_error: \",np.mean(array_train_error), \"   % mean test_error: \",np.mean(array_test_error))\n",
        "\n",
        "ultimate_test_error = bestmodel(mean_Weights, mean_meanTrainImages, testPatternsFinal)\n",
        "\n",
        "print(\"% ultimate_test_error: \",ultimate_test_error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB24JOKPDs4K",
        "outputId": "338edb8e-e117-42ac-c1fd-f0f72b2c8681"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration:  0 Weights:  (10, 10) % train_error:  10.25    % test_error:  7.0\n",
            "iteration:  1 Weights:  (10, 10) % train_error:  10.125    % test_error:  9.5\n",
            "iteration:  2 Weights:  (10, 10) % train_error:  10.1875    % test_error:  9.5\n",
            "iteration:  3 Weights:  (10, 10) % train_error:  10.625    % test_error:  9.0\n",
            "iteration:  4 Weights:  (10, 10) % train_error:  9.5    % test_error:  14.0\n",
            "iteration:  5 Weights:  (10, 10) % train_error:  9.9375    % test_error:  10.5\n",
            "iteration:  6 Weights:  (10, 10) % train_error:  9.875    % test_error:  10.0\n",
            "iteration:  7 Weights:  (10, 10) % train_error:  9.75    % test_error:  9.0\n",
            "iteration:  8 Weights:  (10, 10) % train_error:  9.875    % test_error:  10.5\n",
            "iteration:  9 Weights:  (10, 10) % train_error:  9.8125    % test_error:  9.0\n",
            "% mean train_error:  9.99375    % mean test_error:  9.8\n",
            "% ultimate_test_error:  7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_Weights, array_train_error, array_test_error = [], [], []\n",
        "mean_Weights = [ [ 0 for i in range(10) ] for j in range(10) ]          #### Matrix with mean weigths\n",
        "mean_meanTrainImages = [ [ 0 for i in range(10) ] for j in range(240) ] #### Matrix with mean of the meanTrainImages\n",
        "\n",
        "counts = 0\n",
        "i_iteration = 0\n",
        "\n",
        "\n",
        "while counts < 20:\n",
        "  x, y, z = cross_validation_split(trainPatternsFinal)\n",
        "  Weights, train_error, test_error = trainingFunction(x,y,z)\n",
        "\n",
        "  i_iteration += 1\n",
        "\n",
        "  if test_error < 6:\n",
        "    print(\"iteration: \", i_iteration, \"Weights: \", np.shape(Weights), \"% train_error: \",train_error, \"   % test_error: \",test_error)\n",
        "    array_Weights.append(Weights)\n",
        "    array_train_error.append(train_error)\n",
        "    array_test_error.append(test_error)\n",
        "\n",
        "    mean_Weights += Weights\n",
        "    mean_meanTrainImages += np.array(z)\n",
        "\n",
        "    counts += 1\n",
        "\n",
        "mean_Weights /= nIterations\n",
        "mean_meanTrainImages /= nIterations\n",
        "\n",
        "print(\"% mean train_error: \",np.mean(array_train_error), \"   % mean test_error: \",np.mean(array_test_error))\n",
        "\n",
        "ultimate_test_error = bestmodel(mean_Weights, mean_meanTrainImages, testPatternsFinal)\n",
        "\n",
        "print(\"% ultimate_test_error: \",ultimate_test_error)\n"
      ],
      "metadata": {
        "id": "g00ZoCnOFdao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda112f9-46e5-4f89-b8c4-e275111c2d56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration:  106 Weights:  (10, 10) % train_error:  10.1875    % test_error:  5.5\n",
            "iteration:  388 Weights:  (10, 10) % train_error:  10.125    % test_error:  5.0\n",
            "iteration:  410 Weights:  (10, 10) % train_error:  10.375    % test_error:  5.5\n",
            "iteration:  589 Weights:  (10, 10) % train_error:  10.25    % test_error:  5.0\n",
            "iteration:  716 Weights:  (10, 10) % train_error:  10.375    % test_error:  5.0\n",
            "iteration:  1030 Weights:  (10, 10) % train_error:  10.125    % test_error:  4.5\n",
            "iteration:  1235 Weights:  (10, 10) % train_error:  10.0625    % test_error:  5.0\n",
            "iteration:  1313 Weights:  (10, 10) % train_error:  10.5625    % test_error:  5.0\n",
            "iteration:  1345 Weights:  (10, 10) % train_error:  9.9375    % test_error:  5.5\n",
            "iteration:  1567 Weights:  (10, 10) % train_error:  10.125    % test_error:  5.5\n",
            "iteration:  1569 Weights:  (10, 10) % train_error:  10.4375    % test_error:  5.5\n",
            "iteration:  1678 Weights:  (10, 10) % train_error:  9.9375    % test_error:  5.5\n",
            "iteration:  1764 Weights:  (10, 10) % train_error:  10.0    % test_error:  5.5\n",
            "iteration:  1899 Weights:  (10, 10) % train_error:  10.3125    % test_error:  5.5\n",
            "iteration:  2041 Weights:  (10, 10) % train_error:  10.5    % test_error:  5.5\n",
            "iteration:  2078 Weights:  (10, 10) % train_error:  10.25    % test_error:  5.5\n",
            "iteration:  2192 Weights:  (10, 10) % train_error:  10.3125    % test_error:  5.0\n",
            "iteration:  2244 Weights:  (10, 10) % train_error:  10.1875    % test_error:  4.5\n",
            "iteration:  2334 Weights:  (10, 10) % train_error:  10.3125    % test_error:  5.0\n",
            "iteration:  2446 Weights:  (10, 10) % train_error:  10.125    % test_error:  5.0\n",
            "% mean train_error:  10.225    % mean test_error:  5.2\n",
            "% ultimate_test_error:  7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H76bGjupLaVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}